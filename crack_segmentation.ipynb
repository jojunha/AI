{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crack_Segmentation with UNet\n",
    "## dataset https://www.kaggle.com/datasets/lakshaymiddha/crack-segmentation-dataset?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loading(train_path,image_size = 512):\n",
    "\n",
    "    out_rows = image_size\n",
    "    out_cols = image_size\n",
    "    \n",
    "    img_path = train_path + '/images'\n",
    "    mask_path = train_path + '/masks'\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs = glob.glob(img_path +\"/*.jpg\")\n",
    "    labels = glob.glob(mask_path +\"/*.jpg\")\n",
    "    imgdatas = np.ndarray((len(imgs),out_rows,out_cols,1), dtype=np.uint8)\n",
    "    imglabels = np.ndarray((len(imgs),out_rows,out_cols,1), dtype=np.uint8)\n",
    "    imgnames=[]\n",
    "    \n",
    "    for i, imgname in enumerate(imgs):\n",
    "        if i%100==0:\n",
    "            print('{}/{}'.format(i, len(imgs)))\n",
    "        name = os.path.split(imgname)[1][:-4]\n",
    "        img = load_img(imgname, color_mode = \"grayscale\")\n",
    "        labelname= mask_path + '/' + os.path.split(imgname)[1]\n",
    "        label = load_img(labelname, color_mode = \"grayscale\")\n",
    "        img=img.resize((out_rows,out_cols))\n",
    "        label=label.resize((out_rows,out_cols))\n",
    "\n",
    "        img = img_to_array(img)\n",
    "        label = img_to_array(label)\n",
    "        imgdatas[i] = img\n",
    "        imglabels[i] = label\n",
    "        imgnames.append(name)\n",
    "\n",
    "    imgdatas = imgdatas.astype('float32')\n",
    "    imglabels = imglabels.astype('float32')\n",
    "    \n",
    "    print('img : ', imgdatas.max())\n",
    "    print('mask : ',imglabels.max())\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('normalization start...')\n",
    "    print('-'*30)\n",
    "    imgdatas = imgdatas/255.0\n",
    "    \n",
    "    imglabels[imglabels <= 127] = 0\n",
    "    imglabels[imglabels > 127] = 1\n",
    "    \n",
    "    print('img : ',imgdatas.max())\n",
    "    print('mask : ',imglabels.max())\n",
    "    print('mask : ',imglabels.min())\n",
    "    print('loading done')\n",
    "    \n",
    "    return imgdatas, imglabels, imgnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkfolder(folder):\n",
    "    if not os.path.lexists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "        y_true_f = K.flatten(y_true)\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "        return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def sens(y_true, y_pred): # sensitivity, recall\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    y_target_yn = K.round(K.clip(y_true, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "def sch(epoch):\n",
    "    if epoch>100 and epoch<=250:\n",
    "        return 0.0001\n",
    "    elif epoch>250:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_rows, img_cols):\n",
    "    inputs = Input((img_rows, img_cols,1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation=None, padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation=None, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation=None, padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation=None, padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation=None, padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation=None, padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation=None, padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation=None, padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation=None, padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation=None, padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=None, padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=None, padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=None, padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=None, padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=None, padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=None, padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=None, padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=None, padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep(imgs_train, imgs_mask_train, path, batch_size = 4, epochs = 10, image_size=512): \n",
    "\n",
    "    model = get_unet(image_size, image_size)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss=dice_coef_loss, \n",
    "                        metrics=['accuracy', sens, dice_coef_loss])\n",
    "    \n",
    "    check_model_path = path+'/crack_check'\n",
    "    predict_path = path+'/crack_pred'\n",
    "    mkfolder(check_model_path)\n",
    "    mkfolder(predict_path)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(check_model_path + '/final_{epoch:d}_{loss:f}.hdf5', \n",
    "                                        monitor='val_dice_coef_loss',verbose=1, \n",
    "                                        save_best_only=False)\n",
    "#     earlystopping = EarlyStopping(monitor='val_dice_coef_loss', patience=30, restore_best_weights=True)\n",
    "#     cosine_schedule = CosineAnnealingWarmup(epochs_per_cycle=60, iteration=1,max_lr = 1e-3, min_lr = 1e-6)\n",
    "    \n",
    "    print('Fitting model...')\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=batch_size,  validation_split=0.1,epochs=epochs, verbose=1, \n",
    "              shuffle=True, callbacks = [model_checkpoint])\n",
    "    print('save model')\n",
    "    model.save(predict_path + '/final.h5')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_save(pred_list,name_list,test_path):\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Saving test images...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    pred_img_path = test_path + '/pred'\n",
    "    mkfolder(pred_img_path)\n",
    "\n",
    "    imgs = pred_list\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        img[img <= 0.5] = 0\n",
    "        img[img > 0.5] = 255\n",
    "        img = array_to_img(img)\n",
    "        img.save(pred_img_path+\"/%s_pred.jpg\" %(name_list[i]))\n",
    "\n",
    "def predict_val(model,test_path,image_size=512):\n",
    "    \n",
    "    imgs_test, imgs_label_test, test_name = create_test_data(test_path, image_size, image_size)\n",
    "    print('predict test data')\n",
    "    \n",
    "    imgs_label_pred = model.predict(imgs_test, batch_size=4, verbose=1)\n",
    "    name_list=test_name\n",
    "    df = pd.DataFrame(columns=['name', 'acc', 'sen', 'spe', 'dsc'],dtype = float)\n",
    "    df = df.astype({'name': 'str'})\n",
    "\n",
    "    true_list=imgs_label_test\n",
    "    print(true_list.shape)\n",
    "\n",
    "    pred_list=imgs_label_pred\n",
    "    print(np.unique(pred_list))\n",
    "    pred_list[pred_list > 0.5] = 1\n",
    "    pred_list[pred_list <= 0.5] = 0\n",
    "    \n",
    "    sensitivity=[]\n",
    "    specificity=[]\n",
    "    acc=[]\n",
    "    dsc=[]\n",
    "\n",
    "    for i in range(len(true_list)):\n",
    "        yt=true_list[i].flatten()\n",
    "        yp=pred_list[i].flatten()\n",
    "        mat=confusion_matrix(yt,yp)\n",
    "        if len(mat) == 2:\n",
    "            ac=(mat[1,1]+mat[0,0])/(mat[1,0]+mat[1,1]+mat[0,1]+mat[0,0])\n",
    "            st=mat[1,1]/(mat[1,0]+mat[1,1])\n",
    "            sp=mat[0,0]/(mat[0,1]+mat[0,0])\n",
    "            if mat[1,0]+mat[1,1] == 0:\n",
    "                specificity.append(sp)\n",
    "                acc.append(ac)\n",
    "            else:\n",
    "                sensitivity.append(st)  \n",
    "                specificity.append(sp)\n",
    "                acc.append(ac)\n",
    "        else:\n",
    "            specificity.append(1)\n",
    "            acc.append(1)\n",
    "\n",
    "        yt=true_list[i]\n",
    "        yp=pred_list[i]\n",
    "        if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "            dice = np.sum(yp[yt==1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "            dsc.append(dice)\n",
    "            df=  df.append({'name':name_list[i], 'acc':ac, 'sen':st, 'spe':sp, 'dsc':dice}, ignore_index=True)\n",
    "\n",
    "    print(\"complete\")      \n",
    "    print(\"acc avg : {0:0.4f}\".format(np.mean(acc)))\n",
    "    print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "    print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "    print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "    \n",
    "    \n",
    "\n",
    "    predict_save(pred_list,name_list,test_path)\n",
    "    return test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(test_path, out_rows, out_cols):\n",
    "    \n",
    "    img_path = test_path + '/images'\n",
    "    mask_path = test_path + '/masks'\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Creating test images...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs = glob.glob(img_path +\"/*.jpg\")\n",
    "    labels = glob.glob(mask_path +\"/*.jpg\")\n",
    "    imgdatas = np.ndarray((len(imgs),out_rows,out_cols,1), dtype=np.uint8)\n",
    "    imglabels = np.ndarray((len(imgs),out_rows,out_cols,1), dtype=np.uint8)\n",
    "    imgnames=[]\n",
    "    \n",
    "    for i, imgname in enumerate(imgs):\n",
    "        if i%100==0:\n",
    "            print('{}/{}'.format(i, len(imgs)))\n",
    "        name = os.path.split(imgname)[1][:-4]\n",
    "        img = load_img(imgname, color_mode = \"grayscale\")\n",
    "        labelname= mask_path + '/' + os.path.split(imgname)[1]\n",
    "        label = load_img(labelname, color_mode = \"grayscale\")\n",
    "        img=img.resize((out_rows,out_cols))\n",
    "        label=label.resize((out_rows,out_cols))\n",
    "\n",
    "        img = img_to_array(img)\n",
    "        label = img_to_array(label)\n",
    "        imgdatas[i] = img\n",
    "        imglabels[i] = label\n",
    "        imgnames.append(name)\n",
    "\n",
    "    imgdatas = imgdatas.astype('float32')\n",
    "    imglabels = imglabels.astype('float32')\n",
    "    \n",
    "    print('img : ', imgdatas.max())\n",
    "    print('mask : ',imglabels.max())\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('normalization start...')\n",
    "    print('-'*30)\n",
    "    imgdatas = imgdatas/255.0\n",
    "    \n",
    "    imglabels[imglabels <= 127] = 0\n",
    "    imglabels[imglabels > 127] = 1\n",
    "    \n",
    "    print('img : ',imgdatas.max())\n",
    "    print('mask : ',imglabels.max())\n",
    "    print('mask : ',imglabels.min())\n",
    "    print('loading done')\n",
    "    \n",
    "    return imgdatas, imglabels, imgnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating training images...\n",
      "------------------------------\n",
      "0/9603\n",
      "100/9603\n",
      "200/9603\n",
      "300/9603\n",
      "400/9603\n",
      "500/9603\n",
      "600/9603\n",
      "700/9603\n",
      "800/9603\n",
      "900/9603\n",
      "1000/9603\n",
      "1100/9603\n",
      "1200/9603\n",
      "1300/9603\n",
      "1400/9603\n",
      "1500/9603\n",
      "1600/9603\n",
      "1700/9603\n",
      "1800/9603\n",
      "1900/9603\n",
      "2000/9603\n",
      "2100/9603\n",
      "2200/9603\n",
      "2300/9603\n",
      "2400/9603\n",
      "2500/9603\n",
      "2600/9603\n",
      "2700/9603\n",
      "2800/9603\n",
      "2900/9603\n",
      "3000/9603\n",
      "3100/9603\n",
      "3200/9603\n",
      "3300/9603\n",
      "3400/9603\n",
      "3500/9603\n",
      "3600/9603\n",
      "3700/9603\n",
      "3800/9603\n",
      "3900/9603\n",
      "4000/9603\n",
      "4100/9603\n",
      "4200/9603\n",
      "4300/9603\n",
      "4400/9603\n",
      "4500/9603\n",
      "4600/9603\n",
      "4700/9603\n",
      "4800/9603\n",
      "4900/9603\n",
      "5000/9603\n",
      "5100/9603\n",
      "5200/9603\n",
      "5300/9603\n",
      "5400/9603\n",
      "5500/9603\n",
      "5600/9603\n",
      "5700/9603\n",
      "5800/9603\n",
      "5900/9603\n",
      "6000/9603\n",
      "6100/9603\n",
      "6200/9603\n",
      "6300/9603\n",
      "6400/9603\n",
      "6500/9603\n",
      "6600/9603\n",
      "6700/9603\n",
      "6800/9603\n",
      "6900/9603\n",
      "7000/9603\n",
      "7100/9603\n",
      "7200/9603\n",
      "7300/9603\n",
      "7400/9603\n",
      "7500/9603\n",
      "7600/9603\n",
      "7700/9603\n",
      "7800/9603\n",
      "7900/9603\n",
      "8000/9603\n",
      "8100/9603\n",
      "8200/9603\n",
      "8300/9603\n",
      "8400/9603\n",
      "8500/9603\n",
      "8600/9603\n",
      "8700/9603\n",
      "8800/9603\n",
      "8900/9603\n",
      "9000/9603\n",
      "9100/9603\n",
      "9200/9603\n",
      "9300/9603\n",
      "9400/9603\n",
      "9500/9603\n",
      "9600/9603\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.38 GiB for an array with shape (9603, 512, 512, 1) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13808\\1542772801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13808\\1542772801.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mimgs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs_mask_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_loading\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs_mask_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13808\\3157613218.py\u001b[0m in \u001b[0;36mtrain_data_loading\u001b[1;34m(train_path, image_size)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mimgdatas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgdatas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mimglabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimglabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgdatas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.38 GiB for an array with shape (9603, 512, 512, 1) and data type float32"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 주어진 Train Dataset 경로.\n",
    "    path = 'C:/Users/s_wnsgk4041/crack_segmentation_dataset'\n",
    "    train_path = 'C:/Users/s_wnsgk4041/crack_segmentation_dataset/train'\n",
    "    test_path = 'C:/Users/s_wnsgk4041/crack_segmentation_dataset/test'\n",
    "    image_size = 512\n",
    "    epochs = 1\n",
    "    batch_sizes = 4\n",
    "    \n",
    "    imgs_train, imgs_mask_train, imgs_name = train_data_loading(train_path, image_size = image_size)\n",
    "    model = deep(imgs_train, imgs_mask_train, path, batch_size = batch_sizes, epochs = epochs, image_size=image_size)\n",
    "\n",
    "    test_name = predict_val(model, test_path, image_size = image_size)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
